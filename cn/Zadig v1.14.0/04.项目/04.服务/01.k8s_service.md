---
title: K8s YAML 服务
date: 2021-10-09 17:38:21
permalink: /Zadig v1.14.0/project/service/k8s/
---

本文介绍 K8s YAML 项目中的服务相关操作。

## 新建服务

进入项目的服务管理页面。

![创建服务](../_images/service.png)

系统支持以下三种方式创建 K8s YAML 服务：
- `手工输入`：在创建服务时手工输入服务的 K8s YAML 配置文件。
- `从代码库同步`：从代码库中同步服务的 K8s YAML 配置，一次同步可创建一个服务也可创建多个服务。当代码库中的服务配置有变更时，会通过 Webhook 自动更新 Zadig 平台中的服务配置。
- `使用模板新建`：使用 Zadig 平台中的服务 K8s YAML 模板来创建服务。

### 手工输入服务

点击手工输入按钮 -> 填写服务名称 -> 将服务 K8s YAML 填入编辑器 -> 点击保存按钮，即可新建服务。

![创建服务](../_images/service_1.png)

添加服务成功后即可对环境进行更新：点击`环境更新`，选择要更新的环境，将服务加入到环境中。

![更新环境](../_images/service_4.png)

### 从代码库同步单个服务

::: tip
1. 需要在系统中集成代码源，可参考：[代码源集成](/cn/Zadig%20v1.14.0/settings/codehost/gitlab/)
2. 目前支持从 [GitLab](/cn/Zadig%20v1.14.0/settings/codehost/gitlab/)/[GitHub](/cn/Zadig%20v1.14.0/settings/codehost/github/)/[Gerrit](/cn/Zadig%20v1.14.0/settings/codehost/gerrit/)/[Gitee](/cn/Zadig%20v1.14.0/settings/codehost/gitee/) 代码源同步服务
:::

服务的 YAML 配置组织在单独的文件夹中，点击从代码库同步按钮 -> 选择具体的代码库和服务配置文件所在的目录 -> 点击同步，即可从代码库同步新建服务。

以 [result](https://github.com/koderover/zadig/tree/main/examples/voting-app/freestyle-k8s-specifications/result) 服务为例：

![从代码库同步创建服务](../_images/sync_k8s_service_from_repo.png)

同步后，效果如下：

![从代码库同步创建服务效果](../_images/sync_k8s_service_from_repo_effect.png)


### 从代码库同步多个服务

::: tip
1. 需要在系统中集成代码源，可参考：[代码源集成](/cn/Zadig%20v1.14.0/settings/codehost/gitlab/)
2. 目前支持从 [GitLab](/cn/Zadig%20v1.14.0/settings/codehost/gitlab/)/[GitHub](/cn/Zadig%20v1.14.0/settings/codehost/github/)/[Gerrit](/cn/Zadig%20v1.14.0/settings/codehost/gerrit/)/[Gitee](/cn/Zadig%20v1.14.0/settings/codehost/gitee/) 代码源同步服务
:::

多个服务的 YAML 配置分别组织在同一级目录的单独文件夹中，点击从代码库同步按钮 -> 选择具体的代码库和多个服务配置文件所在的目录 -> 点击同步，即可从代码库同步新建多个服务。

以 [voting](https://github.com/koderover/zadig/tree/main/examples/voting-app/freestyle-k8s-specifications/result)  项目中的 5 个服务为例说明，多个服务的配置文件组织：

```shell
├── 根目录(zadig/examples/voting-app/freestyle-k8s-specifications)
│   ├── db
│   │   ├── db-deployment.yaml
│   │   └── db-service.yaml
│   ├── redis
│   │   ├── redis-deployment.yaml
│   │   └── redis-service.yaml
│   ├── result
│   │   ├── result-deployment.yaml
│   │   └── result-service.yaml
│   ├── vote
│   │   ├── vote-deployment.yaml
│   │   └── vote-service.yaml
│   └── worker
│       └── worker-deployment.yaml
```

从代码库同步多个服务：

![从代码库批量同步创建服务](../_images/sync_multi_k8s_service_from_repo.png)

同步后，效果如下：

![从代码库批量同步创建服务效果](../_images/sync_multi_k8s_service_from_repo_effect.png)

### 使用模板新建服务

::: tip 前提
需要先在系统模板库里创建 K8s YAML 模板，请参考 [K8s YAML 模板管理](/cn/Zadig%20v1.14.0/template/k8s_yaml/)。
:::

点击新建按钮 -> 选择`使用模板新建` -> 填写服务名称，选择模板后填写相关配置 -> 点击新建，即可使用此模板和赋值的变量新建服务。

- 变量配置可使用模板中的默认值，也可以在新建时重新赋值
- 开启`自动同步`后，当在模板库中对使用的模板操作`应用到服务`时，该服务配置将自动基于模板内容同步

![使用 K8s YAML 模板](../_images/use_k8s_yaml_template_1.png)

### 从 Kubernetes 导入

点击新建按钮 -> 选择`从 Kubernetes 导入` -> 填写以下信息后导入即可。

- `选择集群`：要导入的服务所在的 K8s 集群，其中`本地集群`指 Zadig 所在的集群
- `选择命名空间`：要导入的服务所在的 K8s 命名空间
- 点击`添加服务`后填写服务名称，选择资源类型及对应的配置，目前支持选择 deployment/statefulset/service/ingress/secret/configmap/pvc 资源进行导入

![从 K8s 导入](../_images/create_k8s_service_from_k8s.png)

创建服务成功后，可点击查看服务配置的具体内容，按需对其进行修改保存。点击`加入环境`可将该服务加入到环境中。

::: tip
`加入环境`操作会在环境对应的命名空间中部署该服务，若环境的命名空间即为导入服务的命名空间，则会对原始服务进行重启或更新。
:::

![从 K8s 导入](../_images/update_k8s_service_config_from_k8s.png)

## 更新服务
下面分别介绍如何更新使用不同方式新建的服务。

### 更新手工输入的服务

修改服务的 K8s YAML  内容并保存即可。

![修改服务](../_images/service_5.png)

服务修改成功后即可对环境进行更新：点击环境更新，选择要更新的环境对环境中的服务进行更新。

![更新环境中的服务](../_images/service_4.png)

### 更新从代码库同步的服务

* 提交服务配置变更到代码仓库。

![配置变更](../_images/service_upgrade_git.png)

* 变更合并后，会通过 Webhook 的能力自动同步最新配置到 Zadig 系统。也可以在界面上手动同步服务配置，如下图所示。

![服务手动配置同步](../_images/service_upgrade_manual_update.png)

* 在环境中，查看服务配置变更，点击更新服务钮执行更新操作。

![服务版本diff](../_images/service_upgrade_diff.png)
![服务更新](../_images/service_upgrade.png)

### 更新使用模板新建的服务
点击使用模板新建的服务 -> 点击预览/编辑，即可预览/编辑该服务的 K8s YAML 配置。

![配置变更](../_images/update_service_created_by_template.png)

### 更新从 Kubernetes 导入的服务

点击从 Kubernetes 导入的服务即可预览该服务配置的详细内容，修改内容后保存即可。

![更新服务配置](../_images/update_service_config_from_k8s.png)

## 删除服务

点击服务右侧的删除按钮即可将服务删除。

![删除环境](../_images/delete_service.png)

## 服务组件

![服务组件](../_images/k8s_container.png)

可参考[服务组件](/cn/Zadig%20v1.14.0/quick-start/concepts/#服务组件)了解更多信息，此处相关字段说明如下：

- `服务组件`：YAML 配置文件中 container 的名称。
- `镜像名`：系统会按照`仓库地址/命名空间/镜像名:标签名`规则来解析 YAML 配置文件中的 image，标签名前即为镜像名。
- `当前镜像版本`：YAML 配置文件中，container 的 `image` 信息
- `构建信息/操作`：可为服务组件配置构建操作，定义其构建过程，参考：[构建配置](/cn/Zadig%20v1.14.0/project/build)

## 服务编排
> Zadig 系统支持对多个服务的部署顺序进行编排管理，同一启动顺序组的服务在部署时会并行执行，不同启动顺序组的服务会按照组顺序执行，适用于多个服务的启动顺序有先后依赖关系的场景。

点击`服务编排`图标，按需对服务启动顺序进行拖拽组合。

![K8s 服务编排](../_images/k8s_service_orchestration.png)
![K8s 服务编排](../_images/k8s_service_orchestration_1.png)

## 共享服务
> 一个 K8s YAML 服务在某个项目中被设置为共享后，可被添加到使用 K8s YAML 部署的其他项目中去，参与该项目的服务编排。

- 设置共享服务：点击服务右侧的`共享`按钮即可设置该服务为共享服务。

![设置 K8s YAML 共享服务](../_images/share_k8s_yaml_service.png)

- 使用共享服务：在共享服务列表中，点击服务右侧的`+`即可将该服务添加到当前项目中，且服务右侧会有`共享`字段标识。

![添加 K8s YAML 共享服务](../_images/shared_k8s_yaml_service_apply.png)

::: tip 扩展阅读
- 使用共享服务只是复用服务的定义，并不是共享服务实例。在不同项目的环境中，相同的共享服务也是独立的服务实例。
- 使用其他项目中的共享服务时，构建过程会使用该共享服务对应的构建脚本。
:::

## 变量配置
> 包括系统内置变量和全局变量，可在服务 YAML 中进行引用，其中容器名称和镜像信息中只能使用内置变量 `$Product$` 和 `$Service$`。

![变量](../_images/var.png)

### 系统内置变量
包括 `$Namespace$`、`$Product$`、`$Service$`、`$EnvName$`，可直接在 YAML 中进行引用，具体说明如下：

  - `$Namespace$`：项目创建的环境所在的 K8s 空间名称，不可用于容器名称和镜像信息中
  - `$Product$`：项目名称
  - `$Service$`：服务名称
  - `$EnvName$`：创建的环境名称，不可用于容器名称和镜像信息中

### 全局变量
服务的 YAML 配置文件中形如 <span v-pre>`{{.Key}}`</span> 的内容会被自动解析为全局变量。

![变量](../_images/var1.png)

点击`编辑`按钮并填写 Value 内容即可在平台中对变量赋予默认值，点击 Value 右侧的预览图标可查看其具体值。

![变量](../_images/var2.png)

对于不同形式的默认值，在填写时需要满足一定的格式，以下述 YAML 配置中第 24 行的 `envSetting` 变量为例说明。

::: details
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: a
  labels:
    app: a
spec:
  selector:
    matchLabels:
      app: a
  replicas: 1
  template:
    metadata:
      labels:
        app: a
    spec:
      containers:
      - name: nginx-1
        image: ccr.ccs.tencentyun.com/demotest/myapp-1:v0.1__linux_amd64
        imagePullPolicy: Always
        command: ["/myapp-1"]
        args: ["--downstream-addr", "$(DOWNSTREAM_ADDR)", "--headers", "$(HEADERS)"]
        env: 
          {{.envSetting}}
        ports:
        - containerPort: 8080
```
:::

**行内表示法**

`envSetting` 的值用一行完整表示时，直接填写符合 YAML 语法的内容即可。

```bash
[{name: DOWNSTREAM_ADDR, value: "b"},{name: HEADERS, value: "x-request-id"}]
```

**行间表示法**

`envSetting` 的值用多行表示时，填写符合 YAML 语法的代码段即可

```bash
- name: DOWNSTREAM_ADDR
  value: "b"
- name: HEADERS
  value: "x-request-id"
```

点击全局变量右侧的`效果预览`，可查看对配置文件中变量值进行渲染后的效果。

### 变量示例

以下述 YAML 配置文件为例说明：

1. 第 4、11 行引用内置变量 `Product`，无需赋予默认值，在创建环境时内置变量会被自动渲染替换
2. 第 7 行引用全局变量 `portal_host`，在创建环境时可以使用默认值也可以再次修改

```yaml
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: $Product$-index  // 引用系统内置变量 $Product$，环境创建时被渲染
spec:
  rules:
  - host: {{.portal_host}} // 引用全局变量 portal_host，环境创建时被渲染
    http:
      paths:
      - backend:
          serviceName: $Product$-index
          servicePort: 80
        path: /
```
### 变量的使用

#### 创建集成环境时使用

在创建环境时，对项目中所有服务的 YAML 和服务配置文件进行渲染。

![创建集成环境变量渲染](../_images/var_create_env.png)

#### 环境变量更新时使用

在环境中，对于正常运行中的服务，可以自行更新变量值，基本操作中点击`更新环境变量`，即可更新对应环境中的环境变量。

![更新集成环境变量渲染](../_images/var_update_env.png)

## 策略配置
在策略中设置部署服务的超时时间、服务配置更新后是否自动同步更新环境以及交付物命名规则。

![服务策略配置](../_images/service_strategy_config.png)

### 基本说明

- 服务部署超时设置：将服务部署到环境中的超时时间，默认值为 10 分钟。若超出该阈值服务仍未处于 Running 状态，则视为部署超时。
- 服务自动更新设置：开启后，若服务配置变更，Zadig 会自动对包含该服务的环境进行更新，应用最新的服务配置。
- 交付物命名规则设置：自定义该项目中工作流构建产物的命名规则，可通过以下[内置变量](#内置变量)和常量组合的方式设置，注意：
  - 规则一旦设置后，对当前项目的所有服务都生效。
  - 当使用自定义工作流构建服务时，`ENV_NAME` 变量不生效。
  - `JENKINS 生成镜像规则`适用于使用 [Jenkins 构建](/cn/Zadig%20v1.14.0/project/build/#jenkins-构建) 的服务，不可使用下述[内置变量](#内置变量)中的 `REPO_*` 变量。

### 内置变量

|变量名称|描述|
|-------|---|
|`TIMESTAMP`|工作流任务的执行时间戳，形如 `20211029113304`|
|`TASK_ID`|工作流任务的 ID|
|`REPO_BRANCH`|构建过程中指定代码仓库使用的分支信息，JENKINS 生成镜像规则中不适用|
|`REPO_PR`|1. 构建过程中指定代码仓库使用的 Pull Request ID 信息，若指定了多个 Pull Request，则会使用 `-` 将多个 ID 拼接起来<br>2. JENKINS 生成镜像规则中该变量不适用|
|`REPO_TAG`|1. 构建过程中指定代码仓库使用的 Tag 信息<br>2. JENKINS 生成镜像规则中不适用|
|`REPO_COMMIT_ID`|1. 构建过程中指定代码仓库使用的 Commit ID 信息<br>2. JENKINS 生成镜像规则中不适用|
|`PROJECT`|构建所属的 Zadig 项目名称|
|`SERVICE`|构建编译的服务名称|
|`ENV_NAME`|1. 构建部署的环境名称<br>2. 使用自定义工作流构建时不适用|
|`字符常量`|大小写字母、数字、中划线、下划线及点组合生成的 127 个字符以内的常量|

## 服务 YAML 样例
### 无状态服务

概念：服务运行的实例不会在本地存储需要持久化的数据，并且多个实例对于同一个请求响应的结果是完全一致的。可以参考[这篇文章](https://kubernetes.io/zh/docs/tasks/run-application/run-stateless-application-deployment/)了解无状态服务的更多细节。
::: details
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2 # 2 个 Pod 实例
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```
:::

### 有状态服务

概念：服务的实例可以将一部分数据随时进行备份，并且在创建一个新的有状态服务时，可以通过备份恢复这些数据，以达到数据持久化的目的。可以参考[这篇文章](https://kubernetes.io/zh/docs/tasks/run-application/run-replicated-stateful-application/)了解有状态服务的更多细节。
::: details
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql
  labels:
    app: mysql
data:
  master.cnf: |
    # Apply this config only on the master.
    [mysqld]
    log-bin
  slave.cnf: |
    # Apply this config only on slaves.
    [mysqld]
    super-read-only
---
# Headless service for stable DNS entries of StatefulSet members.
apiVersion: v1
kind: Service
metadata:
  name: mysql
  labels:
    app: mysql
spec:
  ports:
  - name: mysql
    port: 3306
  clusterIP: None
  selector:
    app: mysql
---
# Client service for connecting to any MySQL instance for reads.
# For writes, you must instead connect to the master: mysql-0.mysql.
apiVersion: v1
kind: Service
metadata:
  name: mysql-read
  labels:
    app: mysql
spec:
  ports:
  - name: mysql
    port: 3306
  selector:
    app: mysql
---
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: mysql
spec:
  selector:
    matchLabels:
      app: mysql
  serviceName: mysql
  # 1 master and 2 slave
  replicas: 3
  template:
    metadata:
      labels:
        app: mysql
    spec:
      initContainers:
      - name: init-mysql
        image: mysql:5.7
        command:
        - bash
        - "-c"
        - |
          set -ex
          # Generate mysql server-id from pod ordinal index.
          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1
          ordinal=${BASH_REMATCH[1]}
          echo [mysqld] > /mnt/conf.d/server-id.cnf
          # Add an offset to avoid reserved server-id=0 value.
          echo server-id=$((100 + $ordinal)) >> /mnt/conf.d/server-id.cnf
          # Copy appropriate conf.d files from config-map to emptyDir.
          if [[ $ordinal -eq 0 ]]; then
            cp /mnt/config-map/master.cnf /mnt/conf.d/
          else
            cp /mnt/config-map/slave.cnf /mnt/conf.d/
          fi
        volumeMounts:
        - name: conf
          mountPath: /mnt/conf.d
        - name: config-map
          mountPath: /mnt/config-map
      - name: clone-mysql
        image: gcr.azk8s.cn/google-samples/xtrabackup:1.0
        command:
        - bash
        - "-c"
        - |
          set -ex
          # Skip the clone if data already exists.
          [[ -d /var/lib/mysql/mysql ]] && exit 0
          # Skip the clone on master (ordinal index 0).
          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1
          ordinal=${BASH_REMATCH[1]}
          [[ $ordinal -eq 0 ]] && exit 0
          # Clone data from previous peer.
          ncat --recv-only mysql-$(($ordinal-1)).mysql 3307 | xbstream -x -C /var/lib/mysql
          # Prepare the backup.
          xtrabackup --prepare --target-dir=/var/lib/mysql
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
          subPath: mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
      containers:
      - name: mysql
        image: mysql:5.7
        env:
        - name: MYSQL_ALLOW_EMPTY_PASSWORD
          value: "1"
        ports:
        - name: mysql
          containerPort: 3306
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
          subPath: mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 500m
            memory: 1Gi
        livenessProbe:
          exec:
            command: ["mysqladmin", "ping"]
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
        readinessProbe:
          exec:
            # Check we can execute queries over TCP (skip-networking is off).
            command: ["mysql", "-h", "127.0.0.1", "-e", "SELECT 1"]
          initialDelaySeconds: 5
          periodSeconds: 2
          timeoutSeconds: 1
      - name: xtrabackup
        image: gcr.azk8s.cn/google-samples/xtrabackup:1.0
        ports:
        - name: xtrabackup
          containerPort: 3307
        command:
        - bash
        - "-c"
        - |
          set -ex
          cd /var/lib/mysql

          # Determine binlog position of cloned data, if any.
          if [[ -f xtrabackup_slave_info && "x$(<xtrabackup_slave_info)" != "x" ]]; then
            # XtraBackup already generated a partial "CHANGE MASTER TO" query
            # because we're cloning from an existing slave. (Need to remove the tailing semicolon!)
            cat xtrabackup_slave_info | sed -E 's/;$//g' > change_master_to.sql.in
            # Ignore xtrabackup_binlog_info in this case (it's useless).
            rm -f xtrabackup_slave_info xtrabackup_binlog_info
          elif [[ -f xtrabackup_binlog_info ]]; then
            # We're cloning directly from master. Parse binlog position.
            [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1
            rm -f xtrabackup_binlog_info xtrabackup_slave_info
            echo "CHANGE MASTER TO MASTER_LOG_FILE='${BASH_REMATCH[1]}',\
                  MASTER_LOG_POS=${BASH_REMATCH[2]}" > change_master_to.sql.in
          fi

          # Check if we need to complete a clone by starting replication.
          if [[ -f change_master_to.sql.in ]]; then
            echo "Waiting for mysqld to be ready (accepting connections)"
            until mysql -h 127.0.0.1 -e "SELECT 1"; do sleep 1; done

            echo "Initializing replication from clone position"
            mysql -h 127.0.0.1 \
                  -e "$(<change_master_to.sql.in), \
                          MASTER_HOST='mysql-0.mysql', \
                          MASTER_USER='root', \
                          MASTER_PASSWORD='', \
                          MASTER_CONNECT_RETRY=10; \
                        START SLAVE;" || exit 1
            # In case of container restart, attempt this at-most-once.
            mv change_master_to.sql.in change_master_to.sql.orig
          fi

          # Start a server to send backups when requested by peers.
          exec ncat --listen --keep-open --send-only --max-conns=1 3307 -c \
            "xtrabackup --backup --slave-info --stream=xbstream --host=127.0.0.1 --user=root"
        volumeMounts:
        - name: data
          mountPath: /var/lib/mysql
          subPath: mysql
        - name: conf
          mountPath: /etc/mysql/conf.d
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
      volumes:
      - name: conf
        emptyDir: {}
      - name: config-map
        configMap:
          name: mysql
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
```
:::
